# -*- coding: utf-8 -*-
"""STELLAR CLASSIFICATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NMgjaQ8tBrPiVnmiA_WlfAcq462bv1D4

**Import the libraries**
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import IsolationForest
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report,ConfusionMatrixDisplay
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
import pickle

import warnings
warnings.filterwarnings('ignore')

"""**READ THE DATA**"""

data=pd.read_csv("/content/drive/MyDrive/Datasets/star_classification.csv")
data

"""**DATA PREPROCESSING**"""

data.info()

data.drop(["obj_ID","spec_obj_ID"],axis=1,inplace=True)
data

encoder=LabelEncoder()
data['class']=encoder.fit_transform(data['class'])

# Initialize the Isolation Forest model
iso=IsolationForest(random_state=1)

# fit the model
iso.fit(data)

# predict the outliers
data['outliers']=iso.predict(data)
data['outliers']

data['outliers'] = data['outliers'].map({1: 0, -1: 1})

df_cleaned= data[data['outliers'] == 0]

# Drop the 'outlier' column as it is no longer needed
df= df_cleaned.drop(columns=['outliers'])
df

X=df.drop(columns=["class"])
X

y=df["class"]
y

scaler=MinMaxScaler()
X_scaled=scaler.fit_transform(X)
X_scaled

"""**Exploratory Data Analysis**"""

df.describe()

sns.histplot(df['class'])
plt.title('Class of Stallar Objects')
ax = sns.histplot(df['class'])
plt.xlabel('object class')
plt.ylabel('Count')

"""Dominant Class: The majority of stellar objects fall into class 0.00, with a count of approximately 60,000. This indicates that class 0.00-Galaxy is the most common type of stellar object in the dataset.

Second Most Common: Class 1.00-QSA has a significantly lower count, with approximately 20,000 objects. This class is the second most prevalent, but there's a notable drop compared to class 0.00.

Least Common: Class 2.00-Star has the fewest objects, with approximately 15,000. This class is the least represented in the dataset.
"""

plt.figure(figsize=(10,10))
sns.countplot(x='class',data=df,hue='cam_col')
plt.title('Class of Stellar objects according to Camera column to identify the scanline within the run')
plt.show()

"""Class 0 Dominance: Class 0 has the highest count across all camera columns, with particularly high counts in columns 1, 2, and 3. This class is the most prevalent in the dataset, making it a significant focus for analysis.

Class 1 Patterns: Class 1 shows its highest counts in camera columns 2 and 3, although its overall count is significantly lower than class 0. This indicates some level of concentration in specific columns.

Class 2 Distribution: Class 2 has a relatively even distribution across camera columns 2, 3, and 4, but with much lower counts compared to classes 0 and 1. This class is the least represented.

Camera Column Influence: The distribution of counts across different camera columns suggests that the columns themselves may influence the detection or representation of different stellar object classes. This could be due to various factors like the sensitivity, orientation, or coverage of each column.
"""

sns.boxplot(x='class',y='delta',data=df)
plt.show()

"""
The distribution of "delta" values is relatively consistent across the three classes.

The central tendency (median) and variability (IQR) are similar for each class.

The presence of outliers suggests that there might be some unique observations that differ from the typical data points.


"""

plt.title("Jointplot")
sns.jointplot(x='redshift',y='alpha',data=df,hue='cam_col')

"""Scatter Plot Insights:

The plot displays the relationship between two variables: "redshift" on the x-axis and "alpha" on the y-axis.

Each data point is color-coded based on the "cam_col" variable, which ranges from 1 to 6.

The different colors help to identify how the "cam_col" variable influences the relationship between "redshift" and "alpha."

Marginal Histograms:

The histogram on the top of the plot shows the distribution of the "redshift" variable.

The histogram on the right side of the plot displays the distribution of the "alpha" variable.

These histograms provide additional context by showing how each variable is distributed across the dataset.

Patterns and Trends:

The scatter plot suggests there might be some correlation between "redshift" and "alpha," as the points seem to follow a particular pattern.

The color-coding indicates that the "cam_col" variable could influence the observed relationship. For instance, certain columns might have higher densities of data points in specific regions of the plot.

**Correlation matrix**
"""

corr_matrix=df.corr()
plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix,annot=True)
plt.title(" stellar correlation matrix")

corr_matrix["class"].sort_values(ascending=False)

X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.3,random_state=1)

knn=KNeighborsClassifier()
svc=SVC()
nb=GaussianNB()
dt=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=13)
rf=RandomForestClassifier(criterion='entropy',random_state=1,max_depth=11)
ab=AdaBoostClassifier(random_state=1)
gb=GradientBoostingClassifier(random_state=1)
xb=XGBClassifier(random_state=1)
models=[knn,svc,nb,dt,rf,ab,gb,xb]
for model in models:
  print('*****************',model,'*****************')
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred,digits=4))
  print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))

"""**FEATURE SELECTION**"""

mi_scores = mutual_info_classif(X_scaled,y)

mi_scores = pd.Series(mi_scores, index=X.columns)
mi_scores.sort_values(ascending=False, inplace=True)
mi_scores

plt.figure(figsize=(10, 6))
mi_scores.plot.bar()
plt.title('Mutual Information Scores')
plt.ylabel('Mutual Information')
plt.xlabel('Features')
plt.show()

top_N = 10
top_features = mi_scores.index[:top_N]
X_top = X[top_features]
top_features

"""Recall the X with selected features"""

X = X_top[['u', 'g', 'r', 'i', 'z', 'redshift', 'plate','MJD', 'run_ID', 'fiber_ID']]
X

scaler=MinMaxScaler()
X_scaled=scaler.fit_transform(X)
X_scaled

"""Test-Train split"""

X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.3,random_state=1)

"""Building Models"""

knn=KNeighborsClassifier()
svc=SVC()
nb=GaussianNB()
dt=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=13)
rf=RandomForestClassifier(criterion='entropy',random_state=1,max_depth=11)
ab=AdaBoostClassifier(random_state=1)
gb=GradientBoostingClassifier(random_state=1)
xb=XGBClassifier(random_state=1)
models=[knn,svc,nb,dt,rf,ab,gb,xb]
for model in models:
  print('*****************',model,'*****************')
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred,digits=4))
  print(ConfusionMatrixDisplay.from_predictions(y_test,y_pred))

y.value_counts()

"""This indicates is an unbalanced data

**Oversampling**
"""

os=SMOTE(random_state=1)
X_os,y_os=os.fit_resample(X_scaled,y)

y_os.value_counts()

X_train_os,X_test_os,y_train_os,y_test_os=train_test_split(X_os,y_os,test_size=0.3,random_state=1)

knn_os=KNeighborsClassifier()
svc_os=SVC()
nb_os=GaussianNB()
dt_os=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=13)
rf_os=RandomForestClassifier(criterion='entropy',random_state=1,max_depth=11)
ab_os=AdaBoostClassifier(random_state=1)
gb_os=GradientBoostingClassifier(random_state=1)
xb_os=XGBClassifier(random_state=1)
models=[knn_os,svc_os,nb_os,dt_os,rf_os,ab_os,gb_os,xb_os]
for model in models:
  print('*****************',model,'*****************')
  model.fit(X_train_os,y_train_os)
  y_pred=model.predict(X_test_os)
  print(classification_report(y_test_os,y_pred,digits=4))
  print(ConfusionMatrixDisplay.from_predictions(y_test_os,y_pred))

us=RandomUnderSampler(random_state=1)
X_us,y_us=us.fit_resample(X_scaled,y)

y_us.value_counts()

X_train_us,X_test_us,y_train_us,y_test_us=train_test_split(X_us,y_us,test_size=0.3,random_state=1)

knn_us=KNeighborsClassifier()
svc_us=SVC()
nb_us=GaussianNB()
dt_us=DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=13)
rf_us=RandomForestClassifier(criterion='entropy',random_state=1,max_depth=11)
ab_us=AdaBoostClassifier(random_state=1)
gb_us=GradientBoostingClassifier(random_state=1)
xb_us=XGBClassifier(random_state=1)
models=[knn_us,svc_us,nb_us,dt_us,rf_us,ab_us,gb_us,xb_us]
for model in models:
  print('*****************',model,'*****************')
  model.fit(X_train_us,y_train_us)
  y_pred=model.predict(X_test_us)
  print(classification_report(y_test_us,y_pred,digits=4))
  print(ConfusionMatrixDisplay.from_predictions(y_test_us,y_pred))

"""**Gradient boosting model with oversampling is the best model**

**pickle the best model**
"""

pickle.dump(xb_os,open('xb_model.sav','wb'))
pickle.dump(scaler,open('scaler.sav','wb'))

predict_new=xb_os.predict(scaler.transform([[24.77759,22.83188,22.58444,21.16812,21.61427,0.779136,10445,58158,4518,427]]))
predict_new